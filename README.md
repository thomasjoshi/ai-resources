# Resources to Become a Cracked AI Engineer

## Inference Acceleration
1. [Efficient Memory Management for Large Language Model Serving with PagedAttention](https://arxiv.org/pdf/2309.06180)
2. [FLEX ATTENTION: A PROGRAMMING MODEL FOR GENERATING OPTIMIZED ATTENTION KERNELS](https://arxiv.org/pdf/2412.05496)
3. [VLLM Attention Kernels](https://github.com/vllm-project/vllm/blob/main/csrc/attention/attention_kernels.cuh)
4. [Attention Gym Paged Attention Implementation](https://github.com/pytorch-labs/attention-gym/blob/main/attn_gym/paged_attention/paged_attention.py)
5. [CONTEXT PARALLELISM FOR SCALABLE MILLION-TOKEN INFERENCE](https://arxiv.org/pdf/2411.01783)
6. [The Deep Learning Compiler: A Comprehensive Survey](https://arxiv.org/pdf/2002.03794)
7. [Kernel Library for LLM Serving](https://github.com/flashinfer-ai/flashinfer)

## Distributed AI Inference
1. [DistServe: Disaggregating Prefill and Decoding for Goodput-optimized Large Language Model Serving](https://www.usenix.org/system/files/osdi24-zhong-yinmin.pdf)
2. [Dynamo AI Tutorials](https://www.linkedin.com/posts/vikramsharmam_distributed-inference-101-getting-started-activity-7308019486517858305-JX7e?utm_source=share&utm_medium=member_ios&rcm=ACoAAB-7BosBbrFaamvv690_M7ruCd3EHmcHhg0)

## Synthetic Data Generation
1. [Synthetic Data Generation & Multi-Step RL for Reasoning & Tool Use](https://arxiv.org/pdf/2504.04736)
2. [Physics of Language Models](https://physics.allen-zhu.com/part-4-architecture-design/part-4-1)

## Continual Learning
1. [Lifelong Learning of Large Language Model based Agents: A Roadmap](https://arxiv.org/pdf/2501.07278)
2. [TRACE: A COMPREHENSIVE BENCHMARK FOR CONTINUAL LEARNING IN LARGE LANGUAGE MODELS](https://openreview.net/pdf?id=xelrLobW0n)

## PhD Defenses
1. [On Evaluation and Efficient Post-training for LLMs](https://docs.google.com/presentation/d/1-4qwacAMJ012Pv5W5xvTAhfqmF7M9CqN/edit?slide=id.p1#slide=id.p1)

## LLM Alignment
1. [BPO: Staying Close to the Behavior LLM Creates Better Online LLM Alignment.](https://arxiv.org/pdf/2406.12168)
2. [FSPO: Few-Shot Preference Optimization of
Synthetic Preference Data in LLMs Elicits
Effective Personalization to Real Users](https://arxiv.org/pdf/2502.19312?)

## AI Reasoning
1. [Measuring AI Ability to Complete Long Tasks](https://arxiv.org/pdf/2503.14499) - [Code](https://github.com/METR/eval-analysis-public)
2. [Evolving Deeper LLM Thinking](https://arxiv.org/pdf/2501.09891)

## Agent Browser Tools
1. [Stagehand Docs](https://docs.stagehand.dev/get_started/introduction)

## Agents
1. [ADVANCES AND CHALLENGES IN FOUNDATION AGENTS](https://arxiv.org/pdf/2504.01990)
2. [PhD Dissertation: Language Agents From Next-Token Prediction to Digital Automation](https://ysymyth.github.io/papers/Dissertation-finalized.pdf)
3. [Why Do Multi-Agent LLM Systems Fail?](https://export-test.arxiv.org/pdf/2503.13657)
4. [REST MEETS REACT: SELF-IMPROVEMENT FOR MULTI-STEP REASONING LLM AGENT](https://arxiv.org/pdf/2312.10003)
5. [Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents](https://arxiv.org/pdf/2408.07199)
6. [Rethinking Memory in AI: Taxonomy, Operations, Topics, and Future Directions](https://arxiv.org/pdf/2505.00675)

## Coding Agents
1. [SWE-BENCH MULTIMODAL: DO AI SYSTEMS GENERALIZE TO VISUAL SOFTWARE DOMAINS?](https://arxiv.org/pdf/2410.03859)
2. [SWE-bench Verified](https://openai.com/index/introducing-swe-bench-verified/)
3. [Code Generation with Small Language Models: A Deep Evaluation on Codeforces](https://arxiv.org/pdf/2504.07343)

## Multimodal
1. [WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models](https://arxiv.org/pdf/2401.13919)
2. [Set-of-Mark Prompting Unleashes Extraordinary Visual Grounding in GPT-4V](https://arxiv.org/pdf/2310.11441)
3. [Explorer: Scaling Exploration-driven Web Trajectory Synthesis for Multimodal Web Agents](https://arxiv.org/pdf/2502.11357)

## Compound AI Systems and RAG
1. [HETEROGENEOUS SWARMS: Jointly Optimizing Model Roles and Weights for Multi-LLM Systems](https://arxiv.org/pdf/2502.04510)
2. [LLM-based Optimization of Compound AI Systems: A Survey](https://arxiv.org/pdf/2410.16392)
3. [Microsoft Trace - End-to-end Generative Optimization for AI Agents - DSPy Alternative](https://github.com/microsoft/Trace)

## AI Chip Manufacturing

1. [TCP: A Tensor Contraction Processor for AI Workloads](https://dli5ezlttyahz.cloudfront.net/FuriosaAI-tensor-contraction-processor-isca24.pdf?p=download/FuriosaAI-tensor-contraction-processor-isca24)

## AI Safety
1. [Reasoning Models Don’t Always Say What They Think](https://assets.anthropic.com/m/71876fabef0f0ed4/original/reasoning_models_paper.pdf)

## Old School Machine Learning
1. [Elements of Information Theory](https://cs-114.org/wp-content/uploads/2015/01/Elements_of_Information_Theory_Elements.pdf)
2. [Pattern Classification](http://cscog.likufanele.com/~calvo/Inteligencia_Artificial_files/Duda%20R%20O,%20Hart%20P%20E,%20Stork%20D%20G_Pattern%20Classification%20%282Ed%20Wiley%29.pdf)
3. [Approximation Algorithms](https://www.amazon.com/Approximation-Algorithms-Vijay-V-Vazirani/dp/3642084699)
4. [The Probabilistic Method](https://math.bme.hu/~gabor/oktatas/SztoM/AlonSpencer.ProbMethod3ed.pdf)
5. [Prediction, Learning, and Games](https://www.cambridge.org/core/books/prediction-learning-and-games/A05C9F6ABC752FAB8954C885D0065C8F)
6. [Neural Network Learning: Theoretical Foundations](https://www.cambridge.org/core/books/neural-network-learning/665C8C7EB5E2ABC5367A55ADB04E2866)
7. [Convex Optimization – Boyd and Vandenberghe](https://stanford.edu/~boyd/cvxbook/)
8. [Learning with Kernels](https://mcube.lab.nycu.edu.tw/~cfung/docs/books/scholkopf2002learning_with_kernels.pdf)
    8.1 Provides great intuition for why kernels are useful.

## Statistical Inference
1. [Mathematical Statistics](https://link.springer.com/book/10.1007/b97553)

## Philosophy of AI
1. [AI 2027](https://ai-2027.com/)

## Graph Learning
1. [Google at NeurIPs: Mining and Learning with Graphs at Scale](https://neurips.cc/Expo/Conferences/2020/workshop/20237)

## Compute Orchestration
1. [Cilantro: Performance-Aware Resource Allocation for Large LanguageGeneral Objectives via Online Feedback](https://www.usenix.org/system/files/osdi23-bhardwaj.pdf)

## Mathematic Foundations
1. Numerical Optimization by Jorge Nocedal Stephen Wright
2. Elements of Information Theory

