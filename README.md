# Resources to Become a Cracked AI Engineer

## Inference Acceleration
1. [Efficient Memory Management for Large Language Model Serving with PagedAttention](https://arxiv.org/pdf/2309.06180)
2. [FLEX ATTENTION: A PROGRAMMING MODEL FOR GENERATING OPTIMIZED ATTENTION KERNELS](https://arxiv.org/pdf/2412.05496)
3. [VLLM Attention Kernels](https://github.com/vllm-project/vllm/blob/main/csrc/attention/attention_kernels.cuh)
4. [Attention Gym Paged Attention Implementation](https://github.com/pytorch-labs/attention-gym/blob/main/attn_gym/paged_attention/paged_attention.py)

## PhD Defenses
1. [On Evaluation and Efficient Post-training for LLMs](https://docs.google.com/presentation/d/1-4qwacAMJ012Pv5W5xvTAhfqmF7M9CqN/edit?slide=id.p1#slide=id.p1)

## LLM Alignment
1. [BPO: Staying Close to the Behavior LLM Creates Better Online LLM Alignment.](https://arxiv.org/pdf/2406.12168)
2. [FSPO: Few-Shot Preference Optimization of
Synthetic Preference Data in LLMs Elicits
Effective Personalization to Real Users](https://arxiv.org/pdf/2502.19312?)

## Distributed AI Inference
1. [DistServe: Disaggregating Prefill and Decoding for Goodput-optimized Large Language Model Serving](https://www.usenix.org/system/files/osdi24-zhong-yinmin.pdf)
2. [Dynamo AI Tutorials](https://www.linkedin.com/posts/vikramsharmam_distributed-inference-101-getting-started-activity-7308019486517858305-JX7e?utm_source=share&utm_medium=member_ios&rcm=ACoAAB-7BosBbrFaamvv690_M7ruCd3EHmcHhg0)

## Long Task
1. Measuring AI Ability to Complete Long Tasks - [Paper](https://arxiv.org/pdf/2503.14499) - [Code](https://github.com/METR/eval-analysis-public)

## Agent Browser Tools
1. [Stagehand Docs](https://docs.stagehand.dev/get_started/introduction)

## Agent Overview
1. [ADVANCES AND CHALLENGES IN FOUNDATION AGENTS](https://arxiv.org/pdf/2504.01990)
2. [PhD Dissertation: Language Agents From Next-Token Prediction to Digital Automation](https://ysymyth.github.io/papers/Dissertation-finalized.pdf)
3. [Why Do Multi-Agent LLM Systems Fail?](https://export-test.arxiv.org/pdf/2503.13657)

## Multimodal
1. [WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models](https://arxiv.org/pdf/2401.13919)
2. [Set-of-Mark Prompting Unleashes Extraordinary Visual Grounding in GPT-4V](https://arxiv.org/pdf/2310.11441)
3. [Explorer: Scaling Exploration-driven Web Trajectory Synthesis for Multimodal Web Agents](https://arxiv.org/pdf/2502.11357)

## AI Chip Manufacturing

1. [TCP: A Tensor Contraction Processor for AI Workloads](https://dli5ezlttyahz.cloudfront.net/FuriosaAI-tensor-contraction-processor-isca24.pdf?p=download/FuriosaAI-tensor-contraction-processor-isca24)

## AI Safety
1. [Reasoning Models Don’t Always Say What They Think](https://assets.anthropic.com/m/71876fabef0f0ed4/original/reasoning_models_paper.pdf)

## Old School Machine Learning
1. [Elements of Information Theory](https://cs-114.org/wp-content/uploads/2015/01/Elements_of_Information_Theory_Elements.pdf)
2. [Pattern Classification](http://cscog.likufanele.com/~calvo/Inteligencia_Artificial_files/Duda%20R%20O,%20Hart%20P%20E,%20Stork%20D%20G_Pattern%20Classification%20%282Ed%20Wiley%29.pdf)
3. [Approximation Algorithms](https://www.amazon.com/Approximation-Algorithms-Vijay-V-Vazirani/dp/3642084699)
4. [The Probabilistic Method](https://math.bme.hu/~gabor/oktatas/SztoM/AlonSpencer.ProbMethod3ed.pdf)
5. [Prediction, Learning, and Games](https://www.cambridge.org/core/books/prediction-learning-and-games/A05C9F6ABC752FAB8954C885D0065C8F)
6. [Neural Network Learning: Theoretical Foundations](https://www.cambridge.org/core/books/neural-network-learning/665C8C7EB5E2ABC5367A55ADB04E2866)
7. [Convex Optimization – Boyd and Vandenberghe](https://stanford.edu/~boyd/cvxbook/)
8. [Learning with Kernels](https://mcube.lab.nycu.edu.tw/~cfung/docs/books/scholkopf2002learning_with_kernels.pdf)
    8.1 Provides great intuition for why kernels are useful.

## Statistical Inference
1. [Mathematical Statistics](https://link.springer.com/book/10.1007/b97553)

## Philosophy of AI
1. [AI 2027](https://ai-2027.com/)


## Graph Learning
1. [Mining and Learning with Graphs at Scale](https://neurips.cc/Expo/Conferences/2020/workshop/20237)